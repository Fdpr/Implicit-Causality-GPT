{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3220eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import Random\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import traceback\n",
    "from Annotation import annotate\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "ITEMS_PER_CONDITION = 10\n",
    "\n",
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, prompts):\n",
    "        self.prompts = prompts\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.prompts[idx]\n",
    "        \n",
    "def do_one_condition(model, row, forced_tokens):\n",
    "    rows = []\n",
    "    try:\n",
    "        ...\n",
    "        annotate(row)\n",
    "    except StopIteration:\n",
    "        print(\"Reached the end!\")\n",
    "    return rows\n",
    "\n",
    "models = [\n",
    "    # model name, batch_size, device, device Mapping\n",
    "    (\"stefan-it/german-gpt2-larger\", 64, -1, None),]\n",
    "\n",
    "with open(\"../items/names.json\", encoding=\"utf-8\") as nfile:\n",
    "    namedict = json.load(nfile)\n",
    "male_names = [name for name in namedict[\"male\"]] * 2\n",
    "female_names = [name for name in namedict[\"female\"]] * 2\n",
    "with open(\"../items/verbs_forced_reference.json\", encoding=\"utf-8\") as nfile:\n",
    "    verbdict = json.load(nfile)\n",
    "es_verbs = verbdict[\"es\"]\n",
    "se_verbs = verbdict[\"se\"]\n",
    "\n",
    "female_shuffled = female_names.copy()\n",
    "Random(42).shuffle(female_shuffled)\n",
    "male_shuffled = male_names.copy()\n",
    "Random(84).shuffle(male_shuffled)\n",
    "male_pairing = list(zip(male_names, female_shuffled, [False for name in male_names]))\n",
    "female_pairing = list(zip(female_names, male_shuffled, [True for name in male_names]))\n",
    "\n",
    "conditions = [\n",
    "    (2,  es_verbs, female_pairing, \"NP1\"),\n",
    "    (3,  es_verbs,   male_pairing, \"NP1\"),\n",
    "    (6,  se_verbs, female_pairing, \"NP1\"),\n",
    "    (7,  se_verbs,   male_pairing, \"NP1\"),\n",
    "    (10, es_verbs, female_pairing, \"NP2\"),\n",
    "    (11, es_verbs,   male_pairing, \"NP2\"),\n",
    "    (14, se_verbs, female_pairing, \"NP2\"),\n",
    "    (15, se_verbs,   male_pairing, \"NP2\")\n",
    "]\n",
    "\n",
    "items_per_condition = []\n",
    "  \n",
    "for condition, verbs, pairing, forced_reference in conditions:\n",
    "    rows = []\n",
    "    for verbdict in verbs:\n",
    "        verb, filler, verbclass = verbdict[\"verb\"], verbdict[\"filler\"], verbdict[\"verbclass\"]\n",
    "        for np1, np2, female in pairing:\n",
    "            prompt = f\"{np1} {verb} {np2}{filler}, weil\"\n",
    "            nrow = {\"condition\": condition, \"type\": \"Experiment\", \"prompt\": prompt, \"NP1\": np1, \"NP2\": np2, \n",
    "                    \"NP1gender\": \"f\" if female else \"m\", \"verb\": verb, \"verbclass\": verbclass, \"forced\": forced_reference}\n",
    "            rows.append(nrow)\n",
    "    Random(168).shuffle(rows)\n",
    "    items_per_condition.append(rows)\n",
    "\n",
    "for model_name, batch_size, device, device_map in models:\n",
    "       \n",
    "    print(f\"now loading: {model_name}\")\n",
    "    model = pipeline(\"text-generation\", model = model_name, device = device, device_map = device_map)\n",
    "    model.tokenizer.pad_token_id = model.model.config.eos_token_id\n",
    "    model.tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    male_tokens = list(map(model.tokenizer.encode, [\" er\", \" dieser\", \" jener\", \" der\"]))\n",
    "    female_tokens = list(map(model.tokenizer.encode, [\" sie\", \" diese\", \" jene\", \" die\"]))\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for condition in items_per_condition:\n",
    "        items = deepcopy(condition)\n",
    "        bar = tqdm(total = ITEMS_PER_CONDITION)\n",
    "        item_iter = iter(items)\n",
    "        rows = []\n",
    "        while bar.n < ITEMS_PER_CONDITION:\n",
    "            try:\n",
    "                row = next(item_iter)\n",
    "                if row[\"forced\"] == \"NP1\":\n",
    "                    tokenized_name = model.tokenizer.encode(f\" {row['NP1']}\")\n",
    "                else:\n",
    "                    tokenized_name = model.tokenizer.encode(f\" {row['NP2']}\")\n",
    "                if (row[\"NP1gender\"] == \"m\" and row[\"forced\"] == \"NP1\") or (row[\"NP1gender\"] == \"f\" and row[\"forced\"] == \"NP2\"):\n",
    "                    forced_tokens = male_tokens + [tokenized_name]\n",
    "                else:\n",
    "                    forced_tokens = female_tokens + [tokenized_name]\n",
    "                continuation = model(row[\"prompt\"], force_words_ids = [forced_tokens], remove_invalid_values=True, early_stopping = True, do_sample = False, num_beams = 2, max_new_tokens = 12)[0][\"generated_text\"]\n",
    "                row[\"cont\"] = continuation[len(row[\"prompt\"]) + 1:]\n",
    "                res = annotate(row, False)\n",
    "                print(row[\"prompt\"], row[\"cont\"])\n",
    "                print(row[\"forced\"], res[\"Koreferenz\"])\n",
    "                if res[\"Koreferenz\"] == row[\"forced\"]:\n",
    "                    bar.update(1)\n",
    "                    row.update(res)\n",
    "                    rows.append(row)\n",
    "            except StopIteration:\n",
    "                print(f\"Run out of data in condition {items[0]['condition']}\")\n",
    "                break\n",
    "        data += rows\n",
    "\n",
    "    exp3 = pd.DataFrame(data, columns = [\"condition\", \"type\", \"prompt\", \"cont\", \"NP1\", \"NP2\", \"NP1gender\", \"verb\", \"verbclass\", \"forced\", \"Koreferenz\", \"Anaphorische Form\"])\n",
    "    exp3.to_csv(f\"../data/forced_coreference--{model_name.replace('/', '--')}.csv\", sep=\";\", index=False)\n",
    "    \n",
    "    del model\n",
    "    del exp3\n",
    "    del rows\n",
    "    del items\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cb30684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Annotation import do_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7256f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/coreference--ai-forever--mGPT.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645267d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"np1\":\"NP1\", \"np2\":\"NP2\", \"cat\":\"verbclass\", \"continuation\":\"cont\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e50409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"] = [\"Experiment\"] * len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cont\"] = df.apply(lambda row: row[\"cont\"][len(row[\"prompt\"]) + 1:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed08aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NP1gender\"] = df[\"female\"].apply(lambda b: \"f\" if b else \"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e705ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/coreference--ai-forever--mGPT_annotated.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"../data/coreference--ai-forever--mGPT.csv\"[:-4] + \"_annotated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "131249f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_annotation(df[:100], True).to_csv(\"hi.csv\", index=False, sep=\";\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
