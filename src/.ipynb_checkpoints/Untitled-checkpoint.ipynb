{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424678d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import Random\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "import traceback\n",
    "from Annotation import annotate\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b28c6ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'verblass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/612989199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mverbdict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mverbs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mverb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"verb\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filler\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"verblass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfemale\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{np1} {verb} {np2}{filler}, weil\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'verblass'"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "ITEMS_PER_CONDITION = 10\n",
    "\n",
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, prompts):\n",
    "        self.prompts = prompts\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.prompts[idx]\n",
    "        \n",
    "def do_one_condition(model, row, forced_tokens):\n",
    "    rows = []\n",
    "    try:\n",
    "        ...\n",
    "        annotate(row)\n",
    "    except StopIteration:\n",
    "        print(\"Reached the end!\")\n",
    "    return rows\n",
    "\n",
    "models = [\n",
    "    # model name, batch_size, device, device Mapping\n",
    "    (\"stefan-it/german-gpt2-larger\", 64, 0, None),]\n",
    "\n",
    "with open(\"../items/names.json\", encoding=\"utf-8\") as nfile:\n",
    "    namedict = json.load(nfile)\n",
    "male_names = [name for name in namedict[\"male\"]] * 2\n",
    "female_names = [name for name in namedict[\"female\"]] * 2\n",
    "with open(\"../items/verbs_forced_reference.json\", encoding=\"utf-8\") as nfile:\n",
    "    verbdict = json.load(nfile)\n",
    "es_verbs = verbdict[\"es\"]\n",
    "se_verbs = verbdict[\"se\"]\n",
    "\n",
    "female_shuffled = female_names.copy()\n",
    "Random(42).shuffle(female_shuffled)\n",
    "male_shuffled = male_names.copy()\n",
    "Random(84).shuffle(male_shuffled)\n",
    "male_pairing = list(zip(male_names, female_shuffled, [False for name in male_names]))\n",
    "female_pairing = list(zip(female_names, male_shuffled, [True for name in male_names]))\n",
    "\n",
    "conditions = [\n",
    "    (2,  es_verbs, female_pairing, \"NP1\"),\n",
    "    (3,  es_verbs,   male_pairing, \"NP1\"),\n",
    "    (6,  se_verbs, female_pairing, \"NP1\"),\n",
    "    (7,  se_verbs,   male_pairing, \"NP1\"),\n",
    "    (10, es_verbs, female_pairing, \"NP2\"),\n",
    "    (11, es_verbs,   male_pairing, \"NP2\"),\n",
    "    (14, se_verbs, female_pairing, \"NP2\"),\n",
    "    (15, se_verbs,   male_pairing, \"NP2\")\n",
    "]\n",
    "\n",
    "items_per_condition = []\n",
    "  \n",
    "for condition, verbs, pairing, forced_reference in conditions:\n",
    "    rows = []\n",
    "    for verbdict in verbs:\n",
    "        verb, filler, verbclass = verbdict[\"verb\"], verbdict[\"filler\"], verbdict[\"verbclass\"]\n",
    "        for np1, np2, female in pairing:\n",
    "            prompt = f\"{np1} {verb} {np2}{filler}, weil\"\n",
    "            nrow = {\"condition\": condition, \"type\": \"Experiment\", \"prompt\": prompt, \"NP1\": np1, \"NP2\": np2, \n",
    "                    \"NP1gender\": \"f\" if female else \"m\", \"verb\": verb, \"verbclass\": verbclass, \"forced\": forced_reference}\n",
    "            rows.append(nrow)\n",
    "    Random(168).shuffle(rows)\n",
    "    items_per_condition.append(rows)\n",
    "\n",
    "for model_name, batch_size, device, device_map in models:\n",
    "       \n",
    "    print(f\"now loading: {model_name}\")\n",
    "    model = pipeline(\"text-generation\", model = model_name, device = device, device_map = device_map)\n",
    "    model.tokenizer.pad_token_id = model.model.config.eos_token_id\n",
    "    model.tokenizer.padding_side = \"left\"\n",
    "    \n",
    "    male_tokens = list(map(model.tokenizer.encode, [\" er\", \" dieser\", \" jener\", \" der\"]))\n",
    "    female_tokens = list(map(model.tokenizer.encode, [\" sie\", \" diese\", \" jene\", \" die\"]))\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    for index, condition in items_per_condition:\n",
    "        items = deepcopy(condition)\n",
    "        bar = tqdm(total = ITEMS_PER_CONDITION)\n",
    "        item_iter = iter(items)\n",
    "        rows = []\n",
    "        while bar.n < ITEMS_PER_CONDITION:\n",
    "            try:\n",
    "                row = next(item_iter)\n",
    "                if row[\"forced\"] == \"NP1\":\n",
    "                    tokenized_name = model.tokenizer.encode(f\" {row['NP1']}\")\n",
    "                else:\n",
    "                    tokenized_name = model.tokenizer.encode(f\" {row['NP2']}\")\n",
    "                if (row[\"NP1gender\"] == \"m\" and row[\"forced\"] == \"NP1\") or (row[\"NP1gender\"] == \"f\" and row[\"forced\"] == \"NP2\"):\n",
    "                    forced_tokens = male_tokens + tokenized_name\n",
    "                else:\n",
    "                    forced_tokens = female_tokens + tokenized_name\n",
    "                continuation = model(row[\"prompt\"], force_words_ids = [forced_tokens], remove_invalid_values=True, early_stopping = True, do_sample = False, num_beams = 10, max_new_tokens = 25)[0][\"generated_text\"]\n",
    "                row[\"con\"] = continuation[len(row[\"prompt\"]) + 1:]\n",
    "                res = annotate(row, False)\n",
    "                if res[\"Koreferenz\"] == row[\"forced\"]:\n",
    "                    bar.update(1)\n",
    "                    row.update(res)\n",
    "                    rows.append(row)\n",
    "            except StopIteration:\n",
    "                print(f\"Run out of data in condition {items[0]['condition']}\")\n",
    "                break\n",
    "        data += rows\n",
    "\n",
    "    exp3 = pd.DataFrame(data, columns = [\"condition\", \"type\", \"prompt\", \"cont\", \"NP1\", \"NP2\", \"NP1gender\", \"verb\", \"verbclass\", \"forced\", \"Koreferenz\", \"Anaphorische Form\"])\n",
    "    exp3.to_csv(f\"../data/forced_coreference--{model_name.replace('/', '--')}.csv\", sep=\";\", index=False)\n",
    "    \n",
    "    del model\n",
    "    del exp3\n",
    "    del rows\n",
    "    del items\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070f8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
